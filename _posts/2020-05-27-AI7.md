---
toc: true
toc_sticky: true
categories:
  - AI
title: AI - 기계학습의 지식표현
tags: [AI, 인공지능]
excerpt: "기계학습의 지식표현 방법인 결정 트리, 앙상블 분류기, KNN, 군집화 알고리즘, 베이즈 분류기에 대한 학습 정리"
---

# 기계학습

## 결정 트리

**결정 트리**는 트리 형태로 의사결정 지식을 표현한 것이다. 내부 노드는 비교 속성, 간선은 속성 값, 단말 노드는 부류 또는 대표 값을 의미한다.

- **결정 트리 알고리즘**: 모든 데이터를 포함한 하나의 노드로 구성된 트리에서 시작하여 반복적인 노드 분할 과정을 거침
  - **ID3 알고리즘**, C4.5 알고리즘, C5.0 알고리즘, CART 알고리즘
    - (1)	분할 속성 선택
    - (2)	속성값에 따라 서브 트리 생성
    - (3)	데이터를 속성값에 따라 분배

- **분할 속성 결정**: 분할 결과가 가능하면 동질적인 것으로 만드는 속성 선택
  - **엔트로피**: 동질적인 정도 측정 가능 척도(섞인 정도가 클수록 큰 값)

- **정보 이득**: 엔트로피에서 특정 속성으로 분할한 후의 각 부분집합의 정보량 가중 평균을 뺀 값
  - 정보이득이 클수록 우수한 분할 속성
  - **단점**: 속성값이 많으면 많은 부분집합으로 분할 -> 작은 부분집합은 동질적인 경향이 존재
  - **개선척도**: 정보이득비, 지니 지수
  
- **정보이득비**: 속성값이 많은 속성에 대해 불이익 부여

- **지니 지수**: 데이터 집합에 대한 지니 값
    - 지니 지수 이득: 지니 지수 – 속성A에 대한 지니 지수 값 가중 평균

- **회귀 분석을 위한 결정 트리**: 단말 노드가 부류가 아닌 수치 값
    - 분할 속성 선택: 표준편차 축소를 최대로 하는 속성 선택

<br>

## 앙상블 분류기

주어진 학습 데이터 집합에 대해서 여러 개의 서로 다른 분류기를 만들고 **투표 방식**이나 **가중치 투표 방식**으로 결합

- **붓스트랩**: 주어진 학습 데이터 집합에서 복원 추출하여 다수의 학습 데이터 집합을 만들어 내는 기법
    - **배깅**: 붓스트랩을 통해 만들어진 분류기들로 투표나 가중치 투표를 하여 최정 판정을 하는 기법(랜덤 포레스트: 분류기로 결정 트리를 사용)
    - **부스팅**: k개의 분류기를 분류 정확도에 따라 학습 데이터에 가중치를 변경해가며 순차적으로 만들어 가는 생성 방법(에이더부스트)

<br>

## k-근접이웃 알고리즘(KNN)

새로운 데이터에 대해 최 근접한 k개의 데이터 결과정보를 이용하는 방법

**데이터 간 거리 계산 -> 근접이웃 탐색 -> 근접 이웃 k개 사이 결과 추정**

- **계층적 군집화**: 병합형 계층적 군집화, 분류형 계층적 군집화

- **분할 군집화**: ex) k-means 알고리즘

<br>

## 군집화 알고리즘

데이터를 유사한 것들끼리 모으는 것, 군집 내 유사도는 크게, 군집 간 유사도는 작게 표현

- K-means 알고리즘: 군집화 알고리즘  
    - (1)	군집의 **중심 위치 선정**  
    - (2)	군집 중심을 기준으로 **군집 재구성**  
    - (3)	군집 별 **평균 위치 결정**  
    - (4)	군집 평균 위치로 **군집 중심 조정**  
    - (5)	수렵할 때까지 2-4 과정 반복  
    - 특성: 군집의 개수 **k는 미리 지정, 초기 군집 위치에 민감**

<br>

## 단순 베이즈 분류기

부류 결정지식을 조건부 확률로 **베이즈 정리**를 이용하여 결정


